import pandas as pd
import numpy as np
import logging
from datetime import datetime, date
from dateutil.relativedelta import relativedelta
from sqlalchemy import create_engine, text
from tqdm import tqdm
import time
import sys
import gc
import os
import psutil
from sqlalchemy.pool import QueuePool
from sqlalchemy.exc import OperationalError
import socket

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class RSCalculatorFast:
    def __init__(self, db_url):
        self.db_url = db_url
        self.engine = None
        self._reconnect()
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ checkpoint Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡
        self._create_checkpoint_table()
    
    def _reconnect(self):
        """Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            if self.engine:
                try:
                    self.engine.dispose()
                except:
                    pass
            
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Render
            self.engine = create_engine(
                self.db_url,
                poolclass=QueuePool,
                pool_size=2,  # Ø­Ø¬Ù… Ø£ØµØºØ± Ù„Ù„Ù€ pool
                max_overflow=2,
                pool_recycle=300,  # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯ÙˆÙŠØ± ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚
                pool_pre_ping=True,  # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                pool_timeout=30,
                connect_args={
                    'connect_timeout': 10,
                    'keepalives': 1,
                    'keepalives_idle': 30,
                    'keepalives_interval': 10,
                    'keepalives_count': 5,
                    'sslmode': 'require'
                }
            )
            logger.debug("âœ… Database connection reinitialized")
        except Exception as e:
            logger.error(f"âŒ Failed to reconnect: {e}")
            raise
    
    def _test_connection(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            return True
        except Exception as e:
            logger.warning(f"âš ï¸  Connection test failed: {e}")
            return False
    
    def _execute_with_retry(self, sql, params=None, max_retries=3):
        """ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„"""
        for attempt in range(max_retries):
            try:
                if not self._test_connection():
                    logger.info(f"ğŸ” Attempting to reconnect (attempt {attempt + 1}/{max_retries})")
                    self._reconnect()
                    time.sleep(2 ** attempt)  # Exponential backoff
                
                with self.engine.connect() as conn:
                    result = conn.execute(text(sql), params or {})
                    conn.commit()
                    return result
            except OperationalError as e:
                logger.warning(f"âš ï¸  Operational error on attempt {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    logger.info(f"â³ Waiting before retry...")
                    time.sleep(5)
                    continue
                else:
                    raise
            except Exception as e:
                logger.error(f"âŒ Unexpected error: {e}")
                raise
    
    def _create_checkpoint_table(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ checkpoint Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹"""
        try:
            self._execute_with_retry("""
                CREATE TABLE IF NOT EXISTS calculation_checkpoint (
                    id SERIAL PRIMARY KEY,
                    last_date DATE,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            logger.debug("âœ… Checkpoint table created/verified")
        except Exception as e:
            logger.warning(f"âš ï¸  Could not create checkpoint table: {e}")
    
    def check_memory(self):
        """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            return memory_mb
        except Exception:
            return 0
    
    def show_progress(self):
        """Show current calculation progress"""
        try:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£ÙŠØ§Ù… Ù…Ù† 2003
            result = self._execute_with_retry("""
                SELECT COUNT(DISTINCT date) 
                FROM prices 
                WHERE date >= '2003-01-01'
            """)
            total_days = result.scalar() or 0
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©
            result = self._execute_with_retry("""
                SELECT COUNT(DISTINCT date) 
                FROM rs_daily 
                WHERE rs_rating IS NOT NULL
            """)
            calculated_days = result.scalar() or 0
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØªÙ‚ÙŠÙŠÙ…Ø§Øª RS
            result = self._execute_with_retry("""
                SELECT COUNT(*) 
                FROM rs_daily 
                WHERE rs_rating IS NOT NULL
            """)
            total_ratings = result.scalar() or 0
            
            # Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® Ù…Ø­Ø³ÙˆØ¨
            result = self._execute_with_retry("""
                SELECT MAX(date) 
                FROM rs_daily 
                WHERE rs_rating IS NOT NULL
            """)
            latest_date = result.scalar()
            
            # Ø¢Ø®Ø± checkpoint
            try:
                result = self._execute_with_retry("SELECT MAX(last_date) FROM calculation_checkpoint")
                last_checkpoint = result.scalar()
            except:
                last_checkpoint = None
            
            print(f"\nğŸ“Š **Current Progress Report:**")
            print(f"   ğŸ“… Total days (from 2003): {total_days:,}")
            print(f"   âœ… Days calculated: {calculated_days:,}")
            
            if total_days > 0:
                completion = (calculated_days / total_days) * 100
                print(f"   ğŸ“ˆ Completion: {completion:.1f}%")
            
            print(f"   ğŸ“Š Total RS ratings: {total_ratings:,}")
            
            if latest_date:
                print(f"   ğŸ• Latest calculated date: {latest_date}")
            
            if last_checkpoint:
                print(f"   ğŸ“ Last checkpoint: {last_checkpoint}")
            
            remaining = total_days - calculated_days
            if remaining > 0:
                print(f"   â³ Remaining days: {remaining:,}")
                print(f"   ğŸš€ Estimated time: ~{remaining * 3.5 / 3600:.1f} hours")
            
            # Ø¹Ø±Ø¶ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            memory_usage = self.check_memory()
            print(f"   ğŸ’¾ Memory usage: {memory_usage:.1f} MB")
            
            return total_days, calculated_days
            
        except Exception as e:
            print(f"âš ï¸  Could not get progress: {e}")
            return 0, 0
    
    def save_checkpoint(self, last_date):
        """Save checkpoint for resume"""
        try:
            self._execute_with_retry("DELETE FROM calculation_checkpoint")
            self._execute_with_retry("""
                INSERT INTO calculation_checkpoint (last_date) 
                VALUES (:last_date)
            """, {'last_date': last_date})
            logger.info(f"ğŸ“ Checkpoint saved for date: {last_date}")
        except Exception as e:
            logger.warning(f"âš ï¸  Could not save checkpoint: {e}")
    
    def get_last_checkpoint(self):
        """Get last checkpoint date"""
        try:
            result = self._execute_with_retry("SELECT MAX(last_date) FROM calculation_checkpoint")
            return result.scalar()
        except Exception as e:
            logger.debug(f"â„¹ï¸  Could not get checkpoint: {e}")
            return None
    
    def cleanup_table(self):
        """Clean old RS table and start fresh"""
        try:
            self._execute_with_retry("DROP TABLE IF EXISTS rs_daily CASCADE")
            self._execute_with_retry("DROP TABLE IF EXISTS calculation_checkpoint CASCADE")
            logger.info("ğŸ—‘ï¸  Cleaned rs_daily and checkpoint tables")
            self._create_checkpoint_table()
        except Exception as e:
            logger.warning(f"âš ï¸  Cannot clean table: {e}")
    
    def setup_table(self):
        """Create the main RS Daily table with ALL columns"""
        
        self._execute_with_retry("""
            CREATE TABLE IF NOT EXISTS rs_daily (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20),
                date DATE,
                rs_rating INTEGER,
                rs_raw DECIMAL(10, 6),
                return_3m DECIMAL(10, 6),
                return_6m DECIMAL(10, 6),
                return_9m DECIMAL(10, 6),
                return_12m DECIMAL(10, 6),
                rank_3m INTEGER,
                rank_6m INTEGER,
                rank_9m INTEGER,
                rank_12m INTEGER,
                company_name VARCHAR(255),
                industry_group VARCHAR(255),
                has_rating BOOLEAN GENERATED ALWAYS AS (rs_rating IS NOT NULL) STORED,
                UNIQUE(symbol, date)
            )
        """)
        
        # Ø¥Ù†Ø´Ø§Ø¡ indexes
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_rs_daily_symbol_date ON rs_daily(symbol, date)",
            "CREATE INDEX IF NOT EXISTS idx_rs_daily_date_rating ON rs_daily(date, rs_rating DESC)",
            "CREATE INDEX IF NOT EXISTS idx_rs_daily_rating_filter ON rs_daily(date) WHERE has_rating = TRUE",
            "CREATE INDEX IF NOT EXISTS idx_rs_daily_date_symbol ON rs_daily(date, symbol)"
        ]
        
        for idx_sql in indexes:
            try:
                self._execute_with_retry(idx_sql)
            except Exception as e:
                logger.warning(f"âš ï¸  Cannot create index: {e}")
                continue
        
        logger.info("âœ… Created/updated table with required optimizations")
    
    def calculate_returns_with_nearest_date(self, df_group, current_date, current_price, months):
        """
        Calculate returns with actual date used
        """
        target_date = current_date - relativedelta(months=months)
        
        if isinstance(target_date, pd.Timestamp):
            target_date = target_date.to_pydatetime()
        
        past_data = df_group[df_group['date'] <= target_date]
        
        if len(past_data) == 0:
            return None, None, None
        
        past_row = past_data.iloc[-1]
        past_price = float(past_row['close'])
        actual_date_used = past_row['date']
        
        if past_price <= 0 or current_price <= 0:
            return None, None, None
        
        return_percent = (current_price - past_price) / past_price
        
        return return_percent, actual_date_used, past_price
    
    def calculate_daily_rs(self, target_date):
        """Calculate RS for a specific day"""
        
        logger.info(f"ğŸ“… Calculating RS for day {target_date}")
        
        # 1. Get current day data
        current_query = """
            SELECT 
                p.symbol,
                p.date,
                p.close,
                p.company_name,
                p.industry_group
            FROM prices p
            WHERE p.date = :target_date
            ORDER BY p.symbol
        """
        
        try:
            result = self._execute_with_retry(current_query, {'target_date': target_date})
            df_current = pd.DataFrame(result.fetchall(), columns=result.keys())
        except Exception as e:
            logger.error(f"âŒ Failed to get current data: {e}")
            return []
        
        if len(df_current) == 0:
            logger.warning(f"âš ï¸  No data for date: {target_date}")
            return []
        
        logger.info(f"ğŸ”¢ Stocks count for day {target_date}: {len(df_current)}")
        
        # 2. Get historical data
        symbols = df_current['symbol'].tolist()
        
        if not symbols:
            return []
        
        symbols_placeholders = ', '.join([f"'{s}'" for s in symbols])
        
        hist_query = f"""
            SELECT 
                symbol,
                date,
                close
            FROM prices 
            WHERE symbol IN ({symbols_placeholders})
                AND date <= :target_date 
                AND date >= :start_date
            ORDER BY symbol, date
        """
        
        start_date = pd.to_datetime(target_date) - relativedelta(months=13)
        
        try:
            result = self._execute_with_retry(hist_query, {
                'target_date': target_date, 
                'start_date': start_date
            })
            df_history = pd.DataFrame(result.fetchall(), columns=result.keys())
        except Exception as e:
            logger.error(f"âŒ Failed to get historical data: {e}")
            return []
        
        df_current['date'] = pd.to_datetime(df_current['date'])
        df_history['date'] = pd.to_datetime(df_history['date'])
        
        df_current['close'] = df_current['close'].astype(float)
        df_history['close'] = df_history['close'].astype(float)
        
        # 3. Process each stock
        results = []
        memory_before = self.check_memory()
        
        for _, row in tqdm(df_current.iterrows(), total=len(df_current), desc=f"Processing {target_date}"):
            try:
                symbol = row['symbol']
                current_date = row['date']
                current_price = row['close']
                
                hist_data = df_history[df_history['symbol'] == symbol].copy()
                
                if len(hist_data) < 10:
                    continue
                
                hist_data = hist_data.sort_values('date')
                hist_data.reset_index(drop=True, inplace=True)
                
                returns = {}
                
                for months in [3, 6, 9, 12]:
                    return_pct, actual_date, past_price = self.calculate_returns_with_nearest_date(
                        hist_data, current_date, current_price, months
                    )
                    returns[f'return_{months}m'] = return_pct
                
                has_complete_data = all(r is not None for r in returns.values())
                
                if has_complete_data:
                    rs_raw = (
                        returns['return_3m'] * 0.4 +
                        returns['return_6m'] * 0.2 +
                        returns['return_9m'] * 0.2 +
                        returns['return_12m'] * 0.2
                    )
                else:
                    rs_raw = None
                
                results.append({
                    'symbol': symbol,
                    'date': current_date,
                    'current_price': current_price,
                    **returns,
                    'rs_raw': rs_raw,
                    'company_name': row['company_name'],
                    'industry_group': row['industry_group'],
                    'has_complete_data': has_complete_data
                })
                
            except Exception as e:
                logger.error(f"Error in symbol {row.get('symbol', 'unknown')}: {e}")
                continue
        
        # 4. Calculate RS Rating
        complete_results = [r for r in results if r['has_complete_data']]
        
        if complete_results:
            df_complete = pd.DataFrame(complete_results)
            
            df_complete['rs_rating'] = (
                df_complete['rs_raw']
                .rank(pct=True, method='average')
                .mul(100)
                .round(0)
                .clip(upper=99)
                .astype(int)
            )
            
            for period in ['3m', '6m', '9m', '12m']:
                col = f'return_{period}'
                df_complete[f'rank_{period}'] = (
                    df_complete[col]
                    .rank(pct=True, method='average')
                    .mul(100)
                    .round(0)
                    .clip(upper=99)
                    .astype(int)
                )
            
            rating_dict = df_complete.set_index('symbol')[['rs_rating']].to_dict()['rs_rating']
            ranks_dict = {period: df_complete.set_index('symbol')[f'rank_{period}'].to_dict() 
                         for period in ['3m', '6m', '9m', '12m']}
            
            for r in complete_results:
                symbol = r['symbol']
                if symbol in rating_dict:
                    r['rs_rating'] = int(rating_dict[symbol])
                    for period in ['3m', '6m', '9m', '12m']:
                        r[f'rank_{period}'] = int(ranks_dict[period].get(symbol, 0))
        
        memory_after = self.check_memory()
        logger.info(f"âœ… Calculated RS for {len(complete_results)} stocks out of {len(results)}")
        if memory_before > 0:
            logger.info(f"ğŸ’¾ Memory delta: {memory_after - memory_before:.1f} MB")
        
        return results
    
    def save_daily_results(self, results):
        """Save daily results to database"""
        
        if not results:
            return 0, 0
        
        complete_data = [r for r in results if r.get('has_complete_data', False)]
        
        if not complete_data:
            return 0, len(results)
        
        complete_records = []
        seen = set()
        
        for r in complete_data:
            date_str = r['date']
            if isinstance(date_str, (pd.Timestamp, datetime)):
                date_str = date_str.strftime('%Y-%m-%d')
            
            key = (r['symbol'], date_str)
            if key in seen:
                continue
            seen.add(key)
            
            complete_records.append({
                'symbol': r['symbol'], 
                'date': date_str,
                'rs_rating': r.get('rs_rating'), 
                'rs_raw': r.get('rs_raw'),
                'return_3m': r.get('return_3m'), 
                'return_6m': r.get('return_6m'),
                'return_9m': r.get('return_9m'), 
                'return_12m': r.get('return_12m'),
                'rank_3m': r.get('rank_3m'), 
                'rank_6m': r.get('rank_6m'),
                'rank_9m': r.get('rank_9m'), 
                'rank_12m': r.get('rank_12m'), 
                'company_name': r.get('company_name'), 
                'industry_group': r.get('industry_group')
            })
        
        if not complete_records:
            return 0, len(results)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø§ØªØµØ§Ù„
        try:
            with self.engine.begin() as conn:
                # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ù…Ø¤Ù‚Øª
                conn.execute(text("""
                    CREATE TEMP TABLE temp_rs_data (
                        symbol VARCHAR(20),
                        date DATE,
                        rs_rating INTEGER,
                        rs_raw DECIMAL(10, 6),
                        return_3m DECIMAL(10, 6),
                        return_6m DECIMAL(10, 6),
                        return_9m DECIMAL(10, 6),
                        return_12m DECIMAL(10, 6),
                        rank_3m INTEGER,
                        rank_6m INTEGER,
                        rank_9m INTEGER,
                        rank_12m INTEGER,
                        company_name VARCHAR(255),
                        industry_group VARCHAR(255)
                    ) ON COMMIT DROP
                """))
        except Exception as e:
            logger.warning(f"âš ï¸  Could not create temp table: {e}")
            return self._save_simple(complete_records)
        
        # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¤Ù‚Øª
        try:
            df_to_save = pd.DataFrame(complete_records)
            df_to_save.to_sql('temp_rs_data', self.engine, if_exists='append', index=False)
        except Exception as e:
            logger.warning(f"âš ï¸  Could not insert into temp table: {e}")
            return self._save_simple(complete_records)
        
        # Bulk upsert
        try:
            with self.engine.begin() as conn:
                conn.execute(text("""
                    INSERT INTO rs_daily 
                    (symbol, date, rs_rating, rs_raw, return_3m, return_6m, return_9m, return_12m,
                     rank_3m, rank_6m, rank_9m, rank_12m, company_name, industry_group)
                    SELECT DISTINCT ON (symbol, date) symbol, date::DATE, rs_rating, rs_raw, return_3m, return_6m, return_9m, return_12m,
                           rank_3m, rank_6m, rank_9m, rank_12m, company_name, industry_group
                    FROM temp_rs_data
                    ORDER BY symbol, date
                    ON CONFLICT (symbol, date) DO UPDATE SET
                    rs_rating = EXCLUDED.rs_rating,
                    rs_raw = EXCLUDED.rs_raw,
                    return_3m = EXCLUDED.return_3m,
                    return_6m = EXCLUDED.return_6m,
                    return_9m = EXCLUDED.return_9m,
                    return_12m = EXCLUDED.return_12m,
                    rank_3m = EXCLUDED.rank_3m,
                    rank_6m = EXCLUDED.rank_6m,
                    rank_9m = EXCLUDED.rank_9m,
                    rank_12m = EXCLUDED.rank_12m,
                    industry_group = EXCLUDED.industry_group
                """))
        except Exception as e:
            logger.warning(f"âš ï¸  Bulk insert failed: {e}")
            return self._save_simple(complete_records)
        
        return len(complete_records), len(results)
    
    def _save_simple(self, complete_records):
        """Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø­ÙØ¸ ÙƒØ¨Ø¯ÙŠÙ„"""
        if not complete_records:
            return 0, 0
        
        batch_size = 50  # Ø¯ÙØ¹Ø§Øª Ø£ØµØºØ±
        saved_count = 0
        
        for i in range(0, len(complete_records), batch_size):
            batch = complete_records[i:i + batch_size]
            
            try:
                stmt = text("""
                    INSERT INTO rs_daily 
                    (symbol, date, rs_rating, rs_raw, return_3m, return_6m, return_9m, return_12m,
                     rank_3m, rank_6m, rank_9m, rank_12m, company_name, industry_group)
                    VALUES (:symbol, :date, :rs_rating, :rs_raw, :return_3m, :return_6m, :return_9m, :return_12m,
                     :rank_3m, :rank_6m, :rank_9m, :rank_12m, :company_name, :industry_group)
                    ON CONFLICT (symbol, date) DO UPDATE SET
                    rs_rating = EXCLUDED.rs_rating,
                    rs_raw = EXCLUDED.rs_raw,
                    return_3m = EXCLUDED.return_3m,
                    return_6m = EXCLUDED.return_6m,
                    return_9m = EXCLUDED.return_9m,
                    return_12m = EXCLUDED.return_12m,
                    rank_3m = EXCLUDED.rank_3m,
                    rank_6m = EXCLUDED.rank_6m,
                    rank_9m = EXCLUDED.rank_9m,
                    rank_12m = EXCLUDED.rank_12m,
                    industry_group = EXCLUDED.industry_group
                """)
                
                with self.engine.begin() as conn:
                    conn.execute(stmt, batch)
                
                saved_count += len(batch)
                logger.debug(f"âœ… Saved batch {i//batch_size + 1}: {len(batch)} records")
                
            except Exception as e:
                logger.error(f"âŒ Failed to save batch {i//batch_size + 1}: {e}")
                continue
        
        return saved_count, 0
    
    def calculate_historical_fast(self, start_date='2003-01-01', batch_size=50):  # ØªÙ‚Ù„ÙŠÙ„ batch_size
        """Calculate historical RS with connection management"""
        
        total_days, calculated_days = self.show_progress()
        
        if calculated_days >= total_days and total_days > 0:
            logger.info("ğŸ‰ All days already calculated!")
            return
        
        logger.info(f"ğŸ“Š Starting calculation from {start_date}")
        
        query = """
            SELECT DISTINCT p.date
            FROM prices p
            LEFT JOIN rs_daily r ON p.date = r.date AND r.rs_rating IS NOT NULL
            WHERE p.date >= :start_date 
            AND r.date IS NULL
            ORDER BY p.date
        """
        
        try:
            result = self._execute_with_retry(query, {'start_date': start_date})
            dates_df = pd.DataFrame(result.fetchall(), columns=['date'])
        except Exception as e:
            logger.error(f"âŒ Failed to get dates: {e}")
            return
        
        all_dates = dates_df['date'].tolist()
        
        if not all_dates:
            logger.info("ğŸ‰ No dates to calculate!")
            return
        
        remaining_days = len(all_dates)
        logger.info(f"ğŸ”¢ Remaining days to calculate: {remaining_days:,}")
        
        self.setup_table()
        
        start_time = time.time()
        total_complete = 0
        last_saved_date = None
        
        date_batches = [all_dates[i:i + batch_size] for i in range(0, remaining_days, batch_size)]
        
        for batch_num, date_batch in enumerate(date_batches, 1):
            batch_start_time = time.time()
            
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“¦ Batch {batch_num}/{len(date_batches)}")
            logger.info(f"ğŸ“… Days: {date_batch[0]} to {date_batch[-1]}")
            logger.info(f"ğŸ”¢ Days in batch: {len(date_batch)}")
            logger.info(f"{'='*60}")
            
            batch_complete = 0
            
            for target_date in date_batch:
                try:
                    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ù‚Ø¨Ù„ ÙƒÙ„ ÙŠÙˆÙ…
                    if not self._test_connection():
                        logger.info("ğŸ”„ Reconnecting to database...")
                        self._reconnect()
                    
                    # Ø­Ø³Ø§Ø¨ RS
                    results = self.calculate_daily_rs(target_date)
                    
                    # Ø§Ù„Ø­ÙØ¸
                    complete_count, _ = self.save_daily_results(results)
                    batch_complete += complete_count
                    
                    # Ø­ÙØ¸ checkpoint
                    last_saved_date = target_date
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                    gc.collect()
                    
                    # Ø¥Ø¶Ø§ÙØ© ØªØ£Ø®ÙŠØ± ØµØºÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø£ÙŠØ§Ù…
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"âŒ Error in {target_date}: {e}")
                    continue
            
            total_complete += batch_complete
            
            # Ø­ÙØ¸ checkpoint Ø¨Ø¹Ø¯ ÙƒÙ„ batch
            if last_saved_date:
                try:
                    self.save_checkpoint(last_saved_date)
                except:
                    pass
            
            # ØªÙ‚Ø±ÙŠØ± Batch
            batch_elapsed = time.time() - batch_start_time
            if len(date_batch) > 0:
                avg_time_per_day = batch_elapsed / len(date_batch)
            else:
                avg_time_per_day = 0
            
            logger.info(f"\nğŸ“Š Batch {batch_num} Report:")
            logger.info(f"   âœ… Stocks calculated: {batch_complete:,}")
            logger.info(f"   â±ï¸  Batch time: {batch_elapsed:.1f}s")
            logger.info(f"   ğŸš€ Speed: {avg_time_per_day:.1f}s/day")
            
            remaining = len(date_batches) - batch_num
            if remaining > 0:
                est_remaining = remaining * (batch_elapsed / 60)
                logger.info(f"   â³ Remaining: ~{est_remaining:.1f} minutes")
            
            gc.collect()
        
        elapsed_minutes = (time.time() - start_time) / 60
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ‰ Calculation complete!")
        logger.info("="*80)
        logger.info(f"ğŸ“Š Statistics:")
        logger.info(f"   ğŸ“… Days calculated: {remaining_days}")
        logger.info(f"   âœ… Stocks with RS: {total_complete:,}")
        logger.info(f"   â±ï¸  Total time: {elapsed_minutes:.1f} minutes")
        logger.info("="*80)
    
    def continue_from_checkpoint(self):
        """Continue calculation from last checkpoint"""
        last_checkpoint = self.get_last_checkpoint()
        
        if last_checkpoint:
            if isinstance(last_checkpoint, date):
                next_date = last_checkpoint
            else:
                next_date = pd.to_datetime(last_checkpoint).date()
            
            logger.info(f"ğŸ“ Resuming from checkpoint: {next_date}")
            next_date = next_date + pd.Timedelta(days=1)
            self.calculate_historical_fast(start_date=next_date.strftime('%Y-%m-%d'), batch_size=50)
        else:
            logger.info("â„¹ï¸  No checkpoint found, getting last calculated date...")
            
            try:
                result = self._execute_with_retry("SELECT MAX(date) FROM rs_daily WHERE rs_rating IS NOT NULL")
                last_calculated = result.scalar()
            except:
                last_calculated = None
            
            if last_calculated:
                logger.info(f"ğŸ“Œ Last calculated date found: {last_calculated}")
                next_date = last_calculated + pd.Timedelta(days=1)
                self.calculate_historical_fast(start_date=next_date.strftime('%Y-%m-%d'), batch_size=50)
            else:
                logger.info("â„¹ï¸  No data found, starting from beginning")
                self.calculate_historical_fast(batch_size=50)

def main():
    """Main function"""
    
    DB_URL = "postgresql://youssef:UtnuCIs7PL3879r7R4jjIHi5FBqoHpKy@dpg-d4k8djidbo4c73cqncl0-a.oregon-postgres.render.com/financialdb_bvyn"
    
    print("="*80)
    print("ğŸš€ **RS Calculator with CONNECTION MANAGEMENT**")
    print("="*80)
    
    calculator = RSCalculatorFast(DB_URL)
    
    if len(sys.argv) > 1:
        if sys.argv[1] == '--auto':
            print("\nğŸš€ Auto-run: Continuing calculation where stopped...")
            calculator.continue_from_checkpoint()
            return
        elif sys.argv[1] == '--resume':
            print("\nğŸš€ Resuming from checkpoint...")
            calculator.continue_from_checkpoint()
            return
    
    calculator.show_progress()
    
    print("\nğŸ“‹ **Choose action:**")
    print("1. âš¡ Continue calculation (with connection management)")
    print("2. ğŸ“ Resume from checkpoint")
    print("3. ğŸ“Š Generate verification report")
    print("4. ğŸ—‘ï¸  Clean and start fresh")
    print("5. ğŸ› ï¸  Setup/Rebuild table")
    print("="*80)
    
    choice = input("\nChoose (1-5) [1]: ").strip() or "1"
    
    if choice == "1":
        print("\nâš¡ Starting calculation...")
        
        batch_input = input("Batch size (days per batch) [50]: ").strip()
        batch_size = int(batch_input) if batch_input else 50
        
        start_input = input("Start date (YYYY-MM-DD) [2003-01-01]: ").strip()
        start_date = start_input if start_input else '2003-01-01'
        
        calculator.calculate_historical_fast(
            start_date=start_date,
            batch_size=batch_size
        )
    
    elif choice == "2":
        print("\nğŸ“ Resuming from last checkpoint...")
        calculator.continue_from_checkpoint()
    
    elif choice == "3":
        date_input = input("Verification date (YYYY-MM-DD) or leave for latest: ").strip()
        
        if date_input:
            try:
                sample_date = pd.to_datetime(date_input).date()
            except:
                print("âŒ Invalid date")
                sample_date = None
        else:
            sample_date = None
        
        # TODO: Add verification function
        print("Verification not implemented in this version")
    
    elif choice == "4":
        confirm = input("\nâš ï¸  **WARNING**: Will delete ALL RS data and checkpoints! Continue? (y/n): ").lower()
        if confirm == 'y':
            calculator.cleanup_table()
            calculator.setup_table()
            print("âœ… Cleaned and ready for fresh start")
        else:
            print("âŒ Cancelled")
    
    elif choice == "5":
        calculator.setup_table()
        print("âœ… Table setup completed")
    
    else:
        print("âŒ Invalid choice")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  **Process paused by user**")
        print("ğŸ’¾ Progress saved")
        print("ğŸ”„ Run with --resume to continue")
    except Exception as e:
        print(f"\n\nâŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()