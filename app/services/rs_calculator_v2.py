import pandas as pd
import numpy as np
from sqlalchemy.orm import Session
from sqlalchemy import desc
from app.models.price import Price
from app.models.rs_daily import RSDaily
import logging
import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def calculate_and_save_rs_v2(db: Session, target_date=None):
    """
    Ø­Ø³Ø§Ø¨ RS Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙØ¹Ù„ÙŠØ© (Trading Days Sequence).
    ÙŠØ·Ø§Ø¨Ù‚ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥ÙƒØ³Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:
    1. Seq = Ø¹Ø¯Ø§Ø¯ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„ÙƒÙ„ Ø³Ù‡Ù….
    2. Shift 63/126/189/252 ÙŠÙˆÙ… ØªØ¯Ø§ÙˆÙ„ (Ù…Ø´ Ø£ÙŠØ§Ù… ØªÙ‚ÙˆÙŠÙ…).
    3. RS Raw = Ù…ØªÙˆØ³Ø· Ù…ÙˆØ²ÙˆÙ†.
    4. RS Rating = ØªØ±ØªÙŠØ¨ Ù…Ø¦ÙˆÙŠ ÙŠÙˆÙ…ÙŠ (1-99).
    """
    logger.info("ğŸ”„ Starting RS Calculation V2 (Trading Days Logic)...")
    
    # 1. Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
    # Ù…Ù„Ø­ÙˆØ¸Ø©: Ù„Ø§Ø²Ù… Ù†Ø¬ÙŠØ¨ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙƒÙ„Ù‡ Ø¹Ø´Ø§Ù† Ù†Ø­Ø³Ø¨ Ø§Ù„Ù€ Seq ÙˆØ§Ù„Ù€ Shifts ØµØ­
    query = db.query(
        Price.date,
        Price.symbol,
        Price.close,
        Price.company_name
        # Ù…Ù…ÙƒÙ† Ù†Ø­ØªØ§Ø¬ volume Ù„Ùˆ Ù‡Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Ø´Ø±ÙˆØ· Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹
    ).order_by(Price.symbol, Price.date)
    
    prices = query.all()
    
    if not prices:
        logger.warning("âš ï¸ No price data found in database.")
        return

    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ DataFrame
    df = pd.DataFrame([{
        'date': p.date,
        'symbol': p.symbol,
        'close': float(p.close),
        'company_name': p.company_name
    } for p in prices])
    
    logger.info(f"ğŸ“Š Loaded {len(df)} price records.")

    # 2. Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Trading Logic)
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹ Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ Shift ÙŠØ´ØªØºÙ„ ØµØ­
    df = df.sort_values(by=['symbol', 'date'])
    
    # Group By Symbol Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ù„ÙƒÙ„ Ø³Ù‡Ù… Ø¹Ù„Ù‰ Ø­Ø¯Ø©
    # ØªÙƒØ§ÙØ¦: Ø­Ø³Ø§Ø¨ Seq Ù„ÙƒÙ„ Ø³Ù‡Ù…
    df['seq'] = df.groupby('symbol').cumcount() + 1
    
    # Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ù…Ø¹ Shift (Ø¥Ø²Ø§Ø­Ø© ØµÙÙˆÙ)
    # R3M = Price / Price(shifted 63 rows) - 1
    def calc_return(series, days):
        return (series / series.shift(days)) - 1

    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ù„ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© (Ø³Ù‡Ù…)
    grouped = df.groupby('symbol')['close']
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹ÙˆØ§Ø¦Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙŠØ§Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (63, 126, 189, 252)
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© (Ù…Ø«Ù„Ø§Ù‹ Ø³Ù‡Ù… Ø¬Ø¯ÙŠØ¯)ØŒ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø³ØªÙƒÙˆÙ† NaN
    df['return_3m'] = grouped.transform(lambda x: calc_return(x, 63))
    df['return_6m'] = grouped.transform(lambda x: calc_return(x, 126))
    df['return_9m'] = grouped.transform(lambda x: calc_return(x, 189))
    df['return_12m'] = grouped.transform(lambda x: calc_return(x, 252))

    # 3. Ø­Ø³Ø§Ø¨ RS Raw (Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙˆØ²ÙˆÙ†)
    # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: 0.4*R12M + 0.2*R9M + 0.2*R6M + 0.2*R3M
    # Ø´Ø±Ø·: Ù„Ø§ ÙŠØ­Ø³Ø¨ Ø¥Ù„Ø§ Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø¨ÙŠØ§Ù†Ø§Øª 12 Ø´Ù‡Ø± (R12M Ù…Ø´ NaN)
    # Ù‡Ø°Ø§ ÙŠØ­Ù‚Ù‚ Ø´Ø±Ø· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "Ù„Ø§ ØªØ­Ø³Ø¨ RS Ø¥Ù„Ø§ Ø¨Ø¹Ø¯ Ù…Ø§ ÙŠÙƒÙˆÙ† Ø¹Ù†Ø¯Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙØ§ÙŠØ©"
    df['rs_raw'] = (
        (0.40 * df['return_12m']) +
        (0.20 * df['return_9m']) +
        (0.20 * df['return_6m']) +
        (0.20 * df['return_3m'])
    )
    
    # ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ RS Raw (Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹)
    # ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¥Ø¨Ù‚Ø§Ø¡Ù‡Ø§ Ø¨Ù‚ÙŠÙ… Null Ø£Ùˆ Ø­Ø°ÙÙ‡Ø§ Ù…Ù† Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù€ Rank
    
    # 4. Ø­Ø³Ø§Ø¨ RS Rating (Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø¦ÙˆÙŠ Ø§Ù„ÙŠÙˆÙ…ÙŠ)
    # "Ø¯Ø§ÙŠÙ…Ø§Ù‹ Ù‚Ø§Ø±Ù† Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… ÙÙ‚Ø·"
    
    def calculate_daily_rank(day_group):
        # ØªØµÙÙŠØ© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (NaN) Ù…Ù† Ø§Ù„ØªØ±ØªÙŠØ¨
        valid_rs = day_group.dropna()
        
        if valid_rs.empty:
            return pd.Series(index=day_group.index, dtype=float)
            
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Percentile Rank
        # pct=True Ø¨ÙŠØ±Ø¬Ø¹ Ù‚ÙŠÙ… Ù…Ù† 0 Ù„Ù€ 1
        ranks = valid_rs.rank(pct=True) * 100
        
        # Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ø·Ø§Ù‚ 1-99
        ranks = ranks.round(0).clip(lower=1, upper=99)
        return ranks.astype(int)

    # ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„ÙƒÙ„ ÙŠÙˆÙ… Ø¹Ù„Ù‰ Ø­Ø¯Ø©
    logger.info("âš¡ Calculating RS Ratings per day...")
    df['rs_rating'] = df.groupby('date')['rs_raw'].transform(calculate_daily_rank)
    
    # Ù„Ùˆ Ø­Ø¯Ø¯Ù†Ø§ target_date (Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹)ØŒ Ù†ØµÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¯Ù„ÙˆÙ‚ØªÙŠ
    if target_date:
        logger.info(f"Filtering for date: {target_date}")
        # convert target_date to match dataframe date type if useful
        result_df = df[df['date'] == target_date].copy()
    else:
        # Ù„Ùˆ Ù…ÙÙŠØ´ ØªØ§Ø±ÙŠØ®ØŒ Ù†Ø­Ø¯Ø« Ø§Ù„ÙƒÙ„ (Ø£Ùˆ Ø¢Ø®Ø± ÙØªØ±Ø©)
        # Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ù…Ù„Ø§ÙŠÙŠÙ† Ø§Ù„Ø³Ø¬Ù„Ø§ØªØŒ Ù…Ù…ÙƒÙ† Ù†Ø­Ø¯Ø« Ø¢Ø®Ø± Ø³Ù†Ø© Ø¨Ø³ØŸ
        # Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø·Ù„Ø¨ Ø³ÙƒØ±ÙŠØ¨Øª ÙƒØ§Ù…Ù„ØŒ ÙÙ‡Ù†Ø­ÙØ¸ ÙƒÙ„Ù‡ Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹
        result_df = df.copy()

    # Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ rs_rating (Ù„Ø£Ù†Ù†Ø§ Ù…Ø´ Ù‡Ù†Ø³Ø¬Ù„ RS Ù„Ø³Ù‡Ù… Ù„Ø³Ù‡ Ù…Ø¯Ø±Ø¬ Ø§Ù…Ø¨Ø§Ø±Ø­)
    filtered_results = result_df.dropna(subset=['rs_rating'])
    
    logger.info(f"ğŸ’¾ Saving {len(filtered_results)} RS records to database...")
    
    # 5. Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Bulk Upsert
    from sqlalchemy.dialects.postgresql import insert
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù‚ÙˆØ§Ù…ÙŠØ³ (List of Dicts)
    records_list = []
    for _, row in filtered_results.iterrows():
        records_list.append({
            "date": row['date'],
            "symbol": row['symbol'],
            "rs_raw": float(row['rs_raw']),
            "rs_percentile": int(row['rs_rating']),
            "return_3m": float(row['return_3m'] * 100),
            "return_6m": float(row['return_6m'] * 100),
            "return_9m": float(row['return_9m'] * 100),
            "return_12m": float(row['return_12m'] * 100),
            "created_at": datetime.datetime.now()
        })
        
    logger.info(f"ğŸ’¾ Prepared {len(records_list)} records for bulk upsert...")

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª (Chunks) Ù„Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¯Ø§ØªØ§Ø¨ÙŠØ²
    chunk_size = 5000
    for i in range(0, len(records_list), chunk_size):
        chunk = records_list[i:i + chunk_size]
        
        stmt = insert(RSDaily).values(chunk)
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ø²Ø§Ø¹: Ù„Ùˆ Ø§Ù„Ø±Ù…Ø² ÙˆØ§Ù„ØªØ§Ø±ÙŠØ® Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ† -> Ø­Ø¯Ø« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        stmt = stmt.on_conflict_do_update(
            index_elements=['symbol', 'date'],
            set_={
                "rs_raw": stmt.excluded.rs_raw,
                "rs_percentile": stmt.excluded.rs_percentile,
                "return_3m": stmt.excluded.return_3m,
                "return_6m": stmt.excluded.return_6m,
                "return_9m": stmt.excluded.return_9m,
                "return_12m": stmt.excluded.return_12m
                # created_at Ù„Ø§ ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ø¹Ø´Ø§Ù† Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø£Ùˆ Ù…Ù…ÙƒÙ† Ù†Ø­Ø¯Ø«Ù‡ Ù„Ùˆ Ø¹Ø§ÙŠØ²ÙŠÙ†
            }
        )
        
        db.execute(stmt)
        db.commit() # Commit Ø¨Ø¹Ø¯ ÙƒÙ„ Chunk Ù„ØªØ®ÙÙŠÙ Ø§Ù„Ø¶ØºØ· ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù€ Timeout
        logger.info(f"âœ… Upserted chunk {i} to {i+chunk_size}")
        
    # db.commit() # Ø®Ù„Ø§Øµ Ø¹Ù…Ù„Ù†Ø§ commit Ø¬ÙˆÙ‡
    logger.info("âœ… RS Calculation V2 Completed Successfully!")

if __name__ == "__main__":
    # Test script standalone
    from app.core.database import SessionLocal
    db = SessionLocal()
    try:
        calculate_and_save_rs_v2(db)
    finally:
        db.close()
