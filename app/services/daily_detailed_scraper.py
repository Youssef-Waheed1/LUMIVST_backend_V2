from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time
import logging
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def build_driver(headless=True):
    """
    Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØµÙØ­ ÙƒØ±ÙˆÙ… Ø¨Ù†ÙØ³ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…
    Ù…Ø¹ Ø¯Ø¹Ù… Render deployment
    """
    options = Options()
    if headless:
        options.add_argument("--headless=new")
    
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # Check for Chrome binary from environment variable (for Render)
    chrome_bin = os.environ.get('CHROME_BIN') or os.environ.get('GOOGLE_CHROME_BIN')
    if chrome_bin:
        logger.info(f"ğŸ“ Using Chrome binary from env: {chrome_bin}")
        options.binary_location = chrome_bin
    else:
        # Try common paths on Linux (Render)
        linux_chrome_paths = [
            '/usr/bin/google-chrome',
            '/usr/bin/google-chrome-stable',
            '/usr/bin/chromium-browser',
            '/usr/bin/chromium',
        ]
        for path in linux_chrome_paths:
            if os.path.exists(path):
                logger.info(f"ğŸ“ Found Chrome at: {path}")
                options.binary_location = path
                break
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def clean_number(text):
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ù† Ø§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
    """
    if not text:
        return 0.0
    text = text.replace(',', '').replace('%', '').strip()
    try:
        return float(text)
    except:
        return 0.0

def scrape_daily_details(headless=True):
    """
    Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù…Ù† ØµÙØ­Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙØµÙŠÙ„ÙŠ
    """
    url = "https://www.saudiexchange.sa/Resources/Reports-v2/DetailedDaily_en.html"
    driver = None
    data = []

    try:
        logger.info("ğŸš€ Starting Daily Details Scraper...")
        driver = build_driver(headless)
        
        logger.info(f"ğŸŒ Navigating to {url}")
        driver.get(url)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        tables = driver.find_elements(By.TAG_NAME, "table")
        logger.info(f"ğŸ” Found {len(tables)} tables on the page.")
        
        target_table = None
        max_rows = 0
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø´Ø±ÙƒØ§Øª (Ø¹Ø§Ø¯Ø© Ù‡Ùˆ Ø£ÙƒØ¨Ø± Ø¬Ø¯ÙˆÙ„)
        for tbl in tables:
            try:
                rows = tbl.find_elements(By.TAG_NAME, "tr")
                row_count = len(rows)
                logger.info(f"Table with {row_count} rows found.")
                
                # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø´Ø±ÙƒØ§Øª Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† ÙÙŠÙ‡ ØµÙÙˆÙ ÙƒØªÙŠØ± (Ø£ÙƒØªØ± Ù…Ù† 50 Ù…Ø«Ù„Ø§Ù‹)
                if row_count > 50:
                    # ÙØ­Øµ Ø¥Ø¶Ø§ÙÙŠ: Ù‡Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© Symbol Ø£Ùˆ CompanyØŸ
                    if "Symbol" in tbl.text or "Company" in tbl.text:
                        if row_count > max_rows:
                            max_rows = row_count
                            target_table = tbl
            except:
                continue
        
        if not target_table:
            logger.error("âŒ Could not identify the Companies List table.")
            return []
            
        logger.info(f"âœ… Target table identified with {max_rows} rows.")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¹Ù…Ù„ Scroll Ù„Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
        try:
            driver.execute_script("arguments[0].scrollIntoView();", target_table)
            time.sleep(1)
        except:
            pass

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±
        tbody = target_table.find_element(By.TAG_NAME, "tbody")
        rows = tbody.find_elements(By.TAG_NAME, "tr")
        
        logger.info(f"ğŸ“Š Processing {len(rows)} rows from target table...")
        
        for i, row in enumerate(rows):
            cols = row.find_elements(By.TAG_NAME, "td")
            
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ø§Ù„ÙÙˆØ§ØµÙ„
            if len(cols) < 5: 
                continue
            
            try:
                # Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„ Ø±Ù…Ø² Ø£Ùˆ Ø§Ø³Ù…
                col0_text = cols[0].text.strip()
                
                # Ù„Ùˆ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„ Ø±Ù‚Ù…ØŒ ÙŠØ¨Ù‚Ù‰ Ø¯Ù‡ Ø§Ù„Ø±Ù…Ø² (Symbol)
                if col0_text.isdigit():
                    symbol = col0_text
                    company = cols[1].text.strip()
                    
                    entry = {
                        "Symbol": symbol,
                        "Company": company,
                        "Open": clean_number(cols[2].text),
                        "Highest": clean_number(cols[3].text),
                        "Lowest": clean_number(cols[4].text),
                        "Close": clean_number(cols[5].text),
                        "Change %": clean_number(cols[6].text),
                        "Volume Traded": clean_number(cols[7].text),
                        "Value Traded": clean_number(cols[8].text),
                        "No. of Trades": clean_number(cols[9].text)
                    }
                    data.append(entry)
                    
                    # Debug sample
                    if len(data) == 1:
                        print(f"DEBUG FIRST ROW: {entry}")
            except Exception as e:
                # logger.warning(f"Skipping row {i}: {e}")
                continue
            
        logger.info(f"âœ… Successfully scraped {len(data)} stocks.")
        
    except Exception as e:
        logger.error(f"âŒ Error during scraping: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if driver:
            driver.quit()
            
    return data

if __name__ == "__main__":
    # Test the scraper
    results = scrape_daily_details(headless=False) # Headless=False Ø¹Ø´Ø§Ù† ØªØ´ÙˆÙ Ø§Ù„Ù…ØªØµÙØ­ ÙˆÙ‡Ùˆ Ø´ØºØ§Ù„
    print(f"Sample data: {results[:2] if results else 'No data'}")
