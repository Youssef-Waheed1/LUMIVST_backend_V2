import json
import math
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime
from app.core.redis import redis_cache
from app.core.database import get_db
from app.services.twelve_data.profile_service import get_company_profile
from app.services.twelve_data.quote_service import get_stock_quote, _calculate_turnover
from app.schemas.stock import StockResponse

def clean_symbol(symbol: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù…Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬"""
    if not symbol:
        return ""
    return ''.join(filter(str.isdigit, symbol)).upper()

# â­ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
SAUDI_STOCKS = {
                        "1010", "1020", "1030", "1050", "1060", "1080", "1111", "1120", "1140", 
                        "1150", "1180", "1182", "1183", "1201", "1202", "1210", "1211", "1212",
                        "1213", "1214", "1301", "1302", "1303", "1304", "1320", "1321", "1322",
                        "1323", "1810", "1820", "1830", "1831", "1832", "1833", "2001", "2010", 
                        "2020", "2030", "2040", "2050", "2060", "2070", "2080", "2081", "2082",
                        "2083", "2090", "2100", "2110", "2120", "2130", "2140", "2150", "2160", 
                        "2170", "2180", "2190", "2200", "2210", "2220", "2222", "2223", "2230", 
                        "2240", "2250", "2270", "2280", "2281", "2282", "2283", "2284", "2285", 
                        "2286", "2287", "2290", "2300", "2310", "2320", "2330", "2340", "2350", 
                        "2360", "2370", "2380", "2381", "2382", "3002", "3003", "3004", 
                        "3005", "3007", "3008", "3010", "3020", "3030", "3040", "3050", "3060",
                        "3080", "3090", "3091", "3092", "4001", "4002", "4003", "4004", "4005",
                        "4006", "4007", "4008", "4009", "4011", "4012", "4013", "4014", 
                        "4015", "4016", "4017", "4018", "4019", "4020", "4030", "4031", "4040", 
                        "4050", "4061", "4070", "4071", "4072", "4080", "4081", "4082", "4083", 
                        "4084", "4090", "4100", "4110", "4130", "4140", "4141", "4142", "4143", 
                        "4144", "4145", "4146", "4150", "4160", "4161", "4162", "4163", "4164", 
                        "4165", "4170", "4180", "4190", "4191", "4192", "4193", "4194", "4200", 
                        "4210", "4220", "4230", "4240", "4250", "4260", "4261", "4262", "4263", 
                        "4264", "4270", "4280", "4290", "4291", "4292", "4300", "4310", "4320", 
                        "4321", "4322", "4323", "4324", "4325", "4326", "4330", "4331", "4332", 
                        "4333", "4334", "4335", "4336", "4337", "4338", "4339", "4340", "4342", 
                        "4344", "4345", "4346", "4347", "4348", "4349", "4350", "5110", "6010", 
                        "6012", "6013", "6014", "6015", "6016", "6017", "6018", "6020", "6040", 
                        "6050", "6060", "6070", "6090", "7010", "7020", "7030", "7200", 
                        "7201", "7202", "7203", "7204", "7211", "8010", "8012", "8020", "8030", 
                        "8040", "8050", "8060", "8070", "8100", "8120", "8150", "8160", "8170", 
                        "8180", "8190", "8200", "8210", "8230", "8240", "8250", "8260", "8280", 
                        "8300", "8310", "8311", "8313","6004","1835","1834","6002","4051","6001",
                        "4021","7040","2084"
            
}

class StockCache:
    def __init__(self):
        self.cache_prefix = "tadawul_stocks"
        self.cache_expire = 300
        self.all_cache_expire = 600
        self.db_cache_expire = 3600
    
    def _get_cache_key(self, page: int, limit: int, country: str = "Saudi Arabia") -> str:
        return f"{self.cache_prefix}:page:{page}:limit:{limit}:country:{country}"
    
    def _get_all_cache_key(self, country: str = "Saudi Arabia") -> str:
        return f"{self.cache_prefix}:all:country:{country}"
    
    def _get_symbol_cache_key(self, symbol: str, country: str = "Saudi Arabia") -> str:
        clean_symbol_val = clean_symbol(symbol)
        return f"{self.cache_prefix}:symbol:{clean_symbol_val}:country:{country}"
    
    def _get_bulk_cache_key(self, symbols: List[str], country: str = "Saudi Arabia") -> str:
        """Ù…ÙØªØ§Ø­ cache Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©"""
        symbols_hash = hash(tuple(sorted(symbols)))
        return f"{self.cache_prefix}:bulk:{symbols_hash}:country:{country}"
    
    async def _get_db_connection(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†"""
        try:
            return next(get_db())
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return None
    
    async def _save_to_postgresql(self, symbol: str, profile_data: Dict, quote_data: Dict):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ PostgreSQL"""
        db = None
        try:
            db = await self._get_db_connection()
            if not db:
                return
                
            # Ø­ÙØ¸ Profile
            if profile_data:
                from app.models.profile import CompanyProfile
                existing_profile = db.query(CompanyProfile).filter(CompanyProfile.symbol == symbol).first()
                
                if existing_profile:
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    for key, value in profile_data.items():
                        if hasattr(existing_profile, key) and value is not None:
                            setattr(existing_profile, key, value)
                else:
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯
                    profile = CompanyProfile(
                        symbol=symbol,
                        name=profile_data.get("name", "N/A"),
                        exchange=profile_data.get("exchange", "Tadawul"),
                        sector=profile_data.get("sector"),
                        industry=profile_data.get("industry"),
                        employees=profile_data.get("employees"),
                        website=profile_data.get("website"),
                        description=profile_data.get("description"),
                        state=profile_data.get("state"),
                        country=profile_data.get("country", "Saudi Arabia")
                    )
                    db.add(profile)
            
            # Ø­ÙØ¸ Quote - â­â­ Ø§Ù„ØªØµØ­ÙŠØ­ Ù‡Ù†Ø§
            if quote_data:
                from app.models.quote import StockQuote
                existing_quote = db.query(StockQuote).filter(StockQuote.symbol == symbol).first()
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª 52 Ø£Ø³Ø¨ÙˆØ¹
                fifty_two_week = quote_data.get("fifty_two_week", {})
                
                quote_update_data = {
                    "symbol": symbol,
                    "currency": quote_data.get("currency", "SAR"),
                    "datetime": quote_data.get("datetime"),
                    "timestamp": quote_data.get("timestamp"),
                    "open": quote_data.get("open"),
                    "high": quote_data.get("high"),
                    "low": quote_data.get("low"),
                    "close": quote_data.get("close"),
                    "volume": quote_data.get("volume"),
                    "previous_close": quote_data.get("previous_close"),
                    "change": quote_data.get("change"),
                    "percent_change": quote_data.get("percent_change"),
                    "average_volume": quote_data.get("average_volume"),
                    "is_market_open": quote_data.get("is_market_open", False),
                    
                    # â­â­ Ø­ÙØ¸ ÙƒÙ„ Ø­Ù‚ÙˆÙ„ 52 Ø£Ø³Ø¨ÙˆØ¹
                    "fifty_two_week_low": self._parse_float(fifty_two_week.get("low")),
                    "fifty_two_week_high": self._parse_float(fifty_two_week.get("high")),
                    "fifty_two_week_low_change": self._parse_float(fifty_two_week.get("low_change")),
                    "fifty_two_week_high_change": self._parse_float(fifty_two_week.get("high_change")),
                    "fifty_two_week_low_change_percent": self._parse_float(fifty_two_week.get("low_change_percent")),
                    "fifty_two_week_high_change_percent": self._parse_float(fifty_two_week.get("high_change_percent")),
                    "fifty_two_week_range": fifty_two_week.get("range")
                }
                
                if existing_quote:
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    for key, value in quote_update_data.items():
                        if hasattr(existing_quote, key) and value is not None:
                            setattr(existing_quote, key, value)
                else:
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙŠØ¯
                    quote = StockQuote(**quote_update_data)
                    db.add(quote)
            
            db.commit()
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª {symbol} ÙÙŠ PostgreSQL")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ PostgreSQL: {e}")
            if db:
                db.rollback()
        finally:
            if db:
                db.close()

    def _parse_float(self, value):
        """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ float"""
        if value in [None, "N/A", ""]:
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None

    async def _combine_stock_data(self, profile_data: Dict[str, Any], quote_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¯Ù…Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Profile Ùˆ Quote"""
        
        def parse_value(value):
            if value in [None, "N/A", ""]:
                return None
            return value
        
        def parse_float(value):
            if value in [None, "N/A", ""]:
                return None
            try:
                return float(value)
            except (ValueError, TypeError):
                return None
        
        # â­â­ Ø¨Ù†Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª 52 Ø£Ø³Ø¨ÙˆØ¹ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        fifty_two_week_data = {
            "low": parse_float(quote_data.get("fifty_two_week_low")),
            "high": parse_float(quote_data.get("fifty_two_week_high")),
            "low_change": parse_float(quote_data.get("fifty_two_week_low_change")),
            "high_change": parse_float(quote_data.get("fifty_two_week_high_change")),
            "low_change_percent": parse_float(quote_data.get("fifty_two_week_low_change_percent")),
            "high_change_percent": parse_float(quote_data.get("fifty_two_week_high_change_percent")),
            "range": parse_value(quote_data.get("fifty_two_week_range"))
        }
        
        return {
            "symbol": profile_data.get("symbol") or quote_data.get("symbol"),
            "name": profile_data.get("name", "N/A"),
            "exchange": profile_data.get("exchange", "Tadawul"),
            "sector": parse_value(profile_data.get("sector")),
            "industry": parse_value(profile_data.get("industry")),
            "employees": parse_value(profile_data.get("employees")),
            "website": parse_value(profile_data.get("website")),
            "description": parse_value(profile_data.get("description")),
            "state": parse_value(profile_data.get("state")),
            "country": parse_value(profile_data.get("country", "Saudi Arabia")),
            "currency": quote_data.get("currency", "SAR"),
            "price": parse_float(quote_data.get("close")),
            "change": parse_float(quote_data.get("change")),
            "change_percent": parse_float(quote_data.get("percent_change")),
            "previous_close": parse_float(quote_data.get("previous_close")),
            "volume": parse_value(quote_data.get("volume")),
            "turnover": _calculate_turnover(quote_data.get("volume"), quote_data.get("close")),
            "open": parse_float(quote_data.get("open")),
            "high": parse_float(quote_data.get("high")),
            "low": parse_float(quote_data.get("low")),
            "average_volume": parse_value(quote_data.get("average_volume")),
            "is_market_open": quote_data.get("is_market_open", False),
            
            # â­â­ Ø§Ù„ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
            "fifty_two_week": fifty_two_week_data,
            "fifty_two_week_range": parse_value(quote_data.get("fifty_two_week_range")),
            "fifty_two_week_low": parse_float(quote_data.get("fifty_two_week_low")),
            "fifty_two_week_high": parse_float(quote_data.get("fifty_two_week_high")),
            "fifty_two_week_low_change": parse_float(quote_data.get("fifty_two_week_low_change")),
            "fifty_two_week_high_change": parse_float(quote_data.get("fifty_two_week_high_change")),
            "fifty_two_week_low_change_percent": parse_float(quote_data.get("fifty_two_week_low_change_percent")),
            "fifty_two_week_high_change_percent": parse_float(quote_data.get("fifty_two_week_high_change_percent")),
            
            "last_updated": datetime.now().isoformat()
        }
    
    async def clear_symbols_cache(self, symbols: List[str], clear_db: bool = False):
        """Ù…Ø³Ø­ ÙƒØ§Ø´ Ø±Ù…ÙˆØ² Ù…Ø­Ø¯Ø¯Ø©"""
        cleared_count = 0
        
        for symbol in symbols:
            clean_sym = clean_symbol(symbol)
            
            # Ù…Ø³Ø­ Ù…Ù† Redis
            cache_key = self._get_symbol_cache_key(clean_sym, "Saudi Arabia")
            await redis_cache.delete(cache_key)
            
            # Ù…Ø³Ø­ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ Ø·Ù„Ø¨
            if clear_db:
                db = None
                try:
                    db = await self._get_db_connection()
                    if db:
                        from app.models.profile import CompanyProfile
                        from app.models.quote import StockQuote
                        
                        # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        db.query(CompanyProfile).filter(CompanyProfile.symbol == clean_sym).delete()
                        db.query(StockQuote).filter(StockQuote.symbol == clean_sym).delete()
                        db.commit()
                        
                        print(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} Ù…Ù† PostgreSQL")
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {clean_sym} Ù…Ù† PostgreSQL: {e}")
                    if db:
                        db.rollback()
                finally:
                    if db:
                        db.close()
            
            cleared_count += 1
            print(f"ğŸ§¹ ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ {clean_sym}")
        
        return cleared_count
    
    async def get_bulk_stocks_data(self, symbols: List[str], country: str = "Saudi Arabia") -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©"""
        cache_key = self._get_bulk_cache_key(symbols, country)
        
        # 1. âœ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Redis Ø£ÙˆÙ„Ø§Ù‹
        cached_data = await redis_cache.get(cache_key)
        if cached_data and isinstance(cached_data, dict):
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {len(symbols)} Ø³Ù‡Ù… Ù…Ù† Redis")
            return cached_data
        
        # 2. ğŸŒ Ø¬Ù„Ø¨ Ù…Ù† API
        print(f"ğŸŒ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {len(symbols)} Ø³Ù‡Ù… Ù…Ù† API...")
        
        all_stocks = []
        BATCH_SIZE = 50 # Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©
        
        for i in range(0, len(symbols), BATCH_SIZE):
            batch_symbols = symbols[i:i + BATCH_SIZE]
            
            # Ø¥Ù†Ø´Ø§Ø¡ tasks Ù„ÙƒÙ„ Ø³Ù‡Ù… ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø©
            tasks = []
            for symbol in batch_symbols:
                tasks.append(self.get_stock_by_symbol(symbol, country))
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯ÙØ¹Ø©
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for j, result in enumerate(results):
                symbol = batch_symbols[j]
                if isinstance(result, Exception):
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ù‡Ù… {symbol}: {result}")
                    continue
                if result:
                    all_stocks.append(result)
                else:
                    print(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ù…Ø² {symbol}")
            
            # delay Ø¨ÙŠÙ† Ø§Ù„Ø¯ÙØ¹Ø§Øª
            if i + BATCH_SIZE < len(symbols):
                await asyncio.sleep(2)
            
            print(f"ğŸ“Š ØªÙ‚Ø¯Ù…: {min(i + BATCH_SIZE, len(symbols))}/{len(symbols)}")
        
        result_data = {
            "data": all_stocks,
            "total": len(all_stocks),
            "symbols_requested": len(symbols),
            "symbols_found": len(all_stocks),
            "country": country,
            "timestamp": datetime.now().isoformat()
        }
        
        # Ø­ÙØ¸ ÙÙŠ Redis
        await redis_cache.set(cache_key, result_data, expire=self.cache_expire)
        print(f"ğŸ’¾ ØªÙ… ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª {len(all_stocks)} Ø³Ù‡Ù… ÙÙŠ Redis")
        
        return result_data
    
    async def get_all_saudi_stocks(self, country: str = "Saudi Arabia") -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ SAUDI_STOCKS"""
        symbols_list = list(SAUDI_STOCKS)
        return await self.get_bulk_stocks_data(symbols_list, country)

    async def get_stock_by_symbol(self, symbol: str, country: str = "Saudi Arabia") -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ù‡Ù… Ù…Ø¹ÙŠÙ†"""
        clean_sym = clean_symbol(symbol)
        cache_key = self._get_symbol_cache_key(clean_sym, country)
        
        # 1. âœ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Redis Ø£ÙˆÙ„Ø§Ù‹
        cached_stock = await redis_cache.get(cache_key)
        if cached_stock and isinstance(cached_stock, dict):
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} Ù…Ù† Redis")
            return cached_stock
        
        # 2. ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ PostgreSQL
        print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ PostgreSQL Ù„Ù„Ø±Ù…Ø² {clean_sym}...")
        db = None
        try:
            db = await self._get_db_connection()
            if db:
                from app.models.profile import CompanyProfile
                from app.models.quote import StockQuote
                
                db_profile = db.query(CompanyProfile).filter(CompanyProfile.symbol == clean_sym).first()
                db_quote = db.query(StockQuote).filter(StockQuote.symbol == clean_sym).first()
                
                if db_profile and db_quote:
                    print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} Ù…Ù† PostgreSQL")
                    
                    profile_dict = {c.name: getattr(db_profile, c.name) for c in db_profile.__table__.columns}
                    quote_dict = {c.name: getattr(db_quote, c.name) for c in db_quote.__table__.columns}
                    
                    stock_data = await self._combine_stock_data(profile_dict, quote_dict)
                    
                    await redis_cache.set(cache_key, stock_data, expire=self.db_cache_expire)
                    return stock_data
                    
        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PostgreSQL: {e}")
        finally:
            if db:
                db.close()
        
        # 3. ğŸŒ Ø¬Ù„Ø¨ Ù…Ù† API
        print(f"ğŸŒ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} Ù…Ù† API...")
        try:
            profile_task = get_company_profile(clean_sym, country)
            quote_task = get_stock_quote(clean_sym, country)
            
            api_profile, api_quote = await asyncio.gather(profile_task, quote_task)
            
            if not api_profile and not api_quote:
                print(f"âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ù…Ø² {clean_sym} ÙÙŠ API")
                return None
            
# ÙÙŠ Ø¬Ø²Ø¡ Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† APIØŒ ØºÙŠØ± Ø¥Ù„Ù‰:
            stock_data = {
                "symbol": clean_sym,
                "name": api_profile.get("name", "N/A") if api_profile else "N/A",
                "exchange": "Tadawul",
                "sector": api_profile.get("sector") if api_profile else "N/A",
                "industry": api_profile.get("industry") if api_profile else "N/A",
                "employees": api_profile.get("employees") if api_profile else "N/A",
                "website": api_profile.get("website") if api_profile else "N/A",
                "country": api_profile.get("country", country) if api_profile else country,
                "state": api_profile.get("state") if api_profile else "N/A",
                "currency": api_quote.get("currency", "SAR") if api_quote else "SAR",
                "price": api_quote.get("close") if api_quote else "N/A",
                "change": api_quote.get("change") if api_quote else "N/A",
                "change_percent": api_quote.get("percent_change") if api_quote else "N/A",
                "previous_close": api_quote.get("previous_close") if api_quote else "N/A",
                "volume": api_quote.get("volume") if api_quote else "N/A",
                "turnover": _calculate_turnover(api_quote.get("volume"), api_quote.get("close")) if api_quote else "N/A",
                "open": api_quote.get("open") if api_quote else "N/A",
                "high": api_quote.get("high") if api_quote else "N/A",
                "low": api_quote.get("low") if api_quote else "N/A",
                "average_volume": api_quote.get("average_volume") if api_quote else "N/A",
                "is_market_open": api_quote.get("is_market_open", False) if api_quote else False,
                
                # â­â­ Ø§Ù„ØªØµØ­ÙŠØ­: Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª 52 Ø£Ø³Ø¨ÙˆØ¹ ÙƒØ§Ù…Ù„Ø© Ù…Ù† API
                "fifty_two_week": api_quote.get("fifty_two_week", {}) if api_quote else {},
                "fifty_two_week_range": api_quote.get("fifty_two_week", {}).get("range", "N/A") if api_quote else "N/A",
                "fifty_two_week_low": api_quote.get("fifty_two_week", {}).get("low", "N/A") if api_quote else "N/A",
                "fifty_two_week_high": api_quote.get("fifty_two_week", {}).get("high", "N/A") if api_quote else "N/A",
                "fifty_two_week_low_change": api_quote.get("fifty_two_week", {}).get("low_change", "N/A") if api_quote else "N/A",
                "fifty_two_week_high_change": api_quote.get("fifty_two_week", {}).get("high_change", "N/A") if api_quote else "N/A",
                "fifty_two_week_low_change_percent": api_quote.get("fifty_two_week", {}).get("low_change_percent", "N/A") if api_quote else "N/A",
                "fifty_two_week_high_change_percent": api_quote.get("fifty_two_week", {}).get("high_change_percent", "N/A") if api_quote else "N/A",
                
                "last_updated": datetime.now().isoformat()
            }
            
            # Ø­ÙØ¸ ÙÙŠ PostgreSQL
            try:
                if api_profile or api_quote:
                    await self._save_to_postgresql(clean_sym, api_profile, api_quote)
                    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} ÙÙŠ PostgreSQL")
            except Exception as e:
                print(f"âš ï¸ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ PostgreSQL: {e}")
            
            # Ø­ÙØ¸ ÙÙŠ Redis
            await redis_cache.set(cache_key, stock_data, expire=self.cache_expire)
            print(f"ğŸ’¾ ØªÙ… ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª {clean_sym} ÙÙŠ Redis")
            
            return stock_data
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† API: {e}")
            return None

    async def get_all_stocks(self, country: str = "Saudi Arabia") -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… - Cache Hierarchy: Redis â†’ PostgreSQL â†’ API"""
        cache_key = self._get_all_cache_key(country)
        
        # 1. âœ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Redis Ø£ÙˆÙ„Ø§Ù‹ (Ø§Ù„Ø£Ø³Ø±Ø¹)
        cached_data = await redis_cache.get(cache_key)
        if cached_data and isinstance(cached_data, dict):
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ ÙƒÙ„ Ø£Ø³Ù‡Ù… Tadawul Ù…Ù† Redis")
            return cached_data
        
        # 2. ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ PostgreSQL (Ø§Ù„Ù…Ø®Ø²Ù† Ø§Ù„Ø¯Ø§Ø¦Ù…)
        print(f"ğŸ” Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† PostgreSQL...")
        db = None
        try:
            db = await self._get_db_connection()
            if db:
                from app.models.profile import CompanyProfile
                from app.models.quote import StockQuote
                
                db_profiles = db.query(CompanyProfile).all()
                db_quotes = db.query(StockQuote).all()
                
                if db_profiles and len(db_profiles) > 0:
                    print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(db_profiles)} Ø´Ø±ÙƒØ© Ù…Ù† PostgreSQL")
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ lookup dictionaries
                    quotes_dict = {quote.symbol: quote for quote in db_quotes}
                    
                    all_stocks = []
                    for profile in db_profiles:
                        quote = quotes_dict.get(profile.symbol)
                        if quote:
                            profile_dict = {c.name: getattr(profile, c.name) for c in profile.__table__.columns}
                            quote_dict = {c.name: getattr(quote, c.name) for c in quote.__table__.columns}
                            stock_data = await self._combine_stock_data(profile_dict, quote_dict)
                            all_stocks.append(stock_data)
                    
                    result_data = {
                        "data": all_stocks,
                        "total": len(all_stocks),
                        "timestamp": datetime.now().isoformat(),
                        "country": country
                    }
                    
                    # Ø­ÙØ¸ ÙÙŠ Redis Ù„Ù„Ù…Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
                    await redis_cache.set(cache_key, result_data, expire=self.db_cache_expire)
                    return result_data
                    
        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PostgreSQL: {e}")
        finally:
            if db:
                db.close()
        
        # 3. ğŸŒ Ø¬Ù„Ø¨ Ù…Ù† API (Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ)
        print(f"ğŸŒ Ø¬Ù„Ø¨ ÙƒÙ„ Ø£Ø³Ù‡Ù… Tadawul Ù…Ù† API...")
        api_data = await self._get_all_stocks_from_api(country)
        
        if api_data and api_data.get("data"):
            # Ø­ÙØ¸ ÙÙŠ Redis Ù„Ù„Ù…Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
            await redis_cache.set(cache_key, api_data, expire=self.all_cache_expire)
            print(f"ğŸ’¾ ØªÙ… ØªØ®Ø²ÙŠÙ† ÙƒÙ„ Ø£Ø³Ù‡Ù… Tadawul ÙÙŠ Redis")
        
        return api_data if api_data else {"data": [], "total": 0}
    
    async def _get_all_stocks_from_api(self, country: str = "Saudi Arabia") -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù…Ù† API"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
            saudi_symbols = list(SAUDI_STOCKS)
            
            print(f"ğŸ” Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {len(saudi_symbols)} Ø³Ù‡Ù… Ø³Ø¹ÙˆØ¯ÙŠ Ù…Ù† API...")
            
            all_stocks = []
            BATCH_SIZE = 2  # ØªØ®ÙÙŠØ¶ Ø§Ù„Ø­Ø¬Ù… Ø¹Ù„Ø´Ø§Ù† Ù…Ø§ Ù†ØªØ¹Ø¯Ø§Ø´ rate limit
            
            for i in range(0, len(saudi_symbols), BATCH_SIZE):
                batch_symbols = saudi_symbols[i:i + BATCH_SIZE]
                
                tasks = [self.get_stock_by_symbol(symbol, country) for symbol in batch_symbols]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, Exception):
                        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ù‡Ù…: {result}")
                        continue
                    if result:
                        all_stocks.append(result)
                
                # delay Ø¨ÙŠÙ† Ø§Ù„Ù€ batches
                if i + BATCH_SIZE < len(saudi_symbols):
                    await asyncio.sleep(3)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù€ delay
                    
                print(f"ğŸ“Š ØªÙ‚Ø¯Ù…: {min(i + BATCH_SIZE, len(saudi_symbols))}/{len(saudi_symbols)}")
            
            print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {len(all_stocks)} Ø³Ù‡Ù… Ù…Ù† Ø£ØµÙ„ {len(saudi_symbols)}")
            
            return {
                "data": all_stocks,
                "total": len(all_stocks),
                "timestamp": datetime.now().isoformat(),
                "country": country
            }
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ ÙƒÙ„ Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† API: {str(e)}")
            return {"data": [], "total": 0}

    async def clear_all_cache(self):
        """Ù…Ø³Ø­ ÙƒÙ„ ÙƒØ§Ø´ Ø§Ù„Ø£Ø³Ù‡Ù…"""
        try:
            # Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† Redis
            keys = await redis_cache.redis_client.keys(f"{self.cache_prefix}:*")
            if keys:
                await redis_cache.redis_client.delete(*keys)
            print("ğŸ§¹ ØªÙ… Ù…Ø³Ø­ ÙƒÙ„ ÙƒØ§Ø´ Ø§Ù„Ø£Ø³Ù‡Ù… Ù…Ù† Redis")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ ÙƒØ§Ø´ Ø§Ù„Ø£Ø³Ù‡Ù…: {e}")
            return False
        

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¹Ø§Ù…Ø©
stock_cache = StockCache()